<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Accelerating weighted random sampling without replacement • wrswoR</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">wrswoR</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../articles/internal/wrswoR.html">Get Started</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Accelerating weighted random sampling without replacement</h1>
                        <h4 class="author">Kirill Müller</h4>
            <address class="author_afil">
      IVT, ETH Zurich<br><a class="author_email" href="mailto:#"></a><a href="mailto:kirill.mueller@ivt.baug.ethz.ch">kirill.mueller@ivt.baug.ethz.ch</a>
      </address>
                  
          </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>Random sampling from discrete populations is one of the basic primitives in statistical computing. This article briefly introduces weighted and unweighted sampling with and without replacement. The case of weighted sampling without replacement appears to be most difficult to implement efficiently, which might be one reason why the  implementation performs slowly for large problem sizes. This paper presents four alternative implementations for the case of weighted sampling without replacement, with an analysis of their run time and correctness.</p>
    </div>
    
<div class="contents">
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>Random sampling from discrete populations is one of the basic primitives in statistical computing. This paper focuses on a specific variant: sampling without replacement from a finite population with non-uniform weight distribution. One application for weighted sampling without replacement is the “Truncate-Replicate-Sample” method for stochastic conversion of positive real-valued weights to integer weights in the domain of spatial microsimulation <span class="citation">[@Lovelace_ComputersEnvironmentandUrbanSystems_2013]</span>. Further applications include market surveys, quality control in manufacturing, and on-line advertising <span class="citation">[@Efraimidis_ArXiv10120256Cs_2010]</span>.</p>
<p>Throughout this paper, the term <em>weight</em> refers to the relative probability that an item is sampled. A related problem, sampling from a population with given inclusion probabilities (without specifying an order) is beyond the scope of this paper.</p>
<p>A surprisingly elegant algorithm for the seemingly difficult problem of weighted random sampling without replacement has been devised by , compared to which other solutions (e.g., the heap-based algorithm by ) seem unnecessarily difficult. While the authors provide a prototype implementation in the Java language, no formal assessment of its correctness has been presented so far, and some rework seems necessary to reuse this implementation. This paper fills this gap by providing a thoroughly validated, optimized and ready-to-use implementation for the statistical software package  <span class="citation">[@R_Core_Team_2017]</span>.</p>
<p>First, different techniques for sampling from discrete populations are reviewed. Several implementations for sampling without replacement are discussed, this includes evaluation of run time performance and correctness.</p>
</div>
<div id="sampling-from-discrete-populations" class="section level1">
<h1 class="hasAnchor">
<a href="#sampling-from-discrete-populations" class="anchor"></a>Sampling from discrete populations</h1>
<p> is offered as a definition of sampling from discrete populations with or without replacement from arbitrary weight distributions. (A pair of dice  indicates random draws.)</p>
\begin{algorithm}[t]
  \caption{$\text{sample}(n, s, \text{replace}, p_i)$}
  \label{alg:sample}
  \begin{algorithmic}[1]
    \REQUIRE $n$: Size of the population
    \REQUIRE $s$: Number of items to sample
    \REQUIRE $\text{replace}$: \TRUE{} to request sampling with replacement
    \REQUIRE $p_i$: Weight of each item for $i \in \{1,\ldots,n\}$
    \ENSURE Returns a vector $k_j \in \{1,\ldots,n\}$ for
      $j \in \{1,\ldots,s\}$ that contains the indexes of the items sampled
    \IF{$s = 0$}
      \RETURN vector of length 0
    \ENDIF
    \STATE
      Randomly select $k$ so that, for all $i$,
      $\mathrm{P}(k=i) = \frac{p_i}{\sum_{j}p_j}$ \hfill \pairadice{}
      \label{alg:sample:norm}
    \IF{not replace}\label{alg:sample:if}
      \STATE $n \leftarrow n - 1$
      \STATE remove item $k$ from $p_i$\label{alg:sample:remove}
    \ENDIF\label{alg:sample:if-end}
    \RETURN $k \oplus \text{sample}(n, s - 1, \text{replace}, p_i)$
  \end{algorithmic}
\end{algorithm}
<p>From this definition, it can be observed that sampling with replacement appears to be a simpler problem than sampling without replacement, as the lines  to  in  are not required. Furthermore, if all weights <span class="math inline">\(p_i\)</span> are equal, the problem is simpler as well: The selection probability <span class="math inline">\(\mathrm{P}(i=k)\)</span> of the sampled items in line  always equals <span class="math inline">\(\frac{1}{n}\)</span> and does not have to be computed explicitly.</p>
<p>In the framework of , sampling without replacement with non-uniform weights seems to be the hardest problem. This intuition carries over to the more specialized algorithms for sampling with and without replacement, and with uniform or arbitrary weights, which are presented in the remainder of this section.</p>
<div id="sampling-with-replacement" class="section level2">
<h2 class="hasAnchor">
<a href="#sampling-with-replacement" class="anchor"></a>Sampling with replacement</h2>
<p>The <em>with replacement</em> case corresponds to repeated selection of <span class="math inline">\(k\)</span> from a fixed discrete weight distribution. The uniform case can be implemented easily by transforming the output of a random number generator that returns uniformly distributed floating-point numbers in <span class="math inline">\([0, 1)\)</span>. (Implementing such a random number generator is nontrivial in itself but outside the scope of this paper.)</p>
<p>More work is needed in the non-uniform case: Here, Walker’s alias method <span class="citation">[@Walker__1977]</span>, which is also used in , is an option. Assuming w.l.o.g. <span class="math inline">\(\sum_j p_j = n\)</span>, it is possible to construct a subdivision <span class="math inline">\((l_i, r_i, s_i)\)</span> with <span class="math inline">\(i, l_i, r_i \in \{1,\ldots,n\}\)</span> and <span class="math inline">\(0 &lt; s_i \leq 1\)</span> so that <span class="math display">\[p_i = \sum_{j:l_j=i}{s_j} + \sum_{j:r_j=i}{(1-s_j)}.\]</span> Sampling an item requires sampling from <span class="math inline">\(\{1,\ldots,n\}\)</span> (to choose <span class="math inline">\(i\)</span>) and then sampling from <span class="math inline">\(\left[0, 1\right)\)</span> (to choose <span class="math inline">\(l_i\)</span> or <span class="math inline">\(r_i\)</span>): If the random number is less than <span class="math inline">\(s_i\)</span>, item <span class="math inline">\(l_i\)</span> is chosen, otherwise item <span class="math inline">\(r_i\)</span>. (Figuratively, the probability mass given by <span class="math inline">\(p_i\)</span> is distributed over <span class="math inline">\(n\)</span> “boxes” so that the space in each box <span class="math inline">\(i\)</span> is assigned to at most two items <span class="math inline">\(l_i\)</span> and <span class="math inline">\(r_i\)</span>. The share occupied by item <span class="math inline">\(l_i\)</span> in box <span class="math inline">\(i\)</span> is given by <span class="math inline">\(s_i\)</span>. Some items may be distributed over several boxes. Sampling an item means selecting a box and choosing between the two items in this box.)</p>
<p>As an example, assume <span class="math inline">\(p_1 = 1.2\)</span> and <span class="math inline">\(p_2 = 0.8\)</span>. A possible split is <span class="math inline">\(l = [1, 1]\)</span>, <span class="math inline">\(r = [1, 2]\)</span> and <span class="math inline">\(s = [1, 0.2]\)</span>. Drawing <span class="math inline">\(i \in {1, 2}\)</span> yields both results with probability 0.5. Only for <span class="math inline">\(i = 2\)</span> element 2 is chosen with probability 0.8, which amounts to a joint probability <span class="math inline">\(P(2) = 0.5 \cdot 0.8 = 0.4 = p_2 / (p_1 + p_2)\)</span>.</p>
<p>Walker’s alias method is optimal, requiring only <span class="math inline">\(O(n)\)</span> preprocessing time (in a modification suggested by <span class="citation">@Vose_IEEETrans.Softw.Eng._1991</span>). Hence, for non-uniform weights, the run time is at least <span class="math inline">\(O(n + s)\)</span>, and the input size <span class="math inline">\(n\)</span> will dominate unless <span class="math inline">\(s \gg n\)</span>. More recently, <span class="citation">@Marsaglia_J.Stat.Softw._2004</span> have suggested a table-based method that seems to perform much faster in practice but expresses the weights as rationals with a fixed base and is therefore not usable directly for distributions with a large range. <span class="citation">@Shmerling_StatisticsProbabilityLetters_2013</span> presents a comprehensive review and suggests a general method suitable even for quasi-infinite ranges.</p>
</div>
<div id="sampling-without-replacement" class="section level2">
<h2 class="hasAnchor">
<a href="#sampling-without-replacement" class="anchor"></a>Sampling without replacement</h2>
<p>In the <em>without replacement</em> case, each selected item is removed from the collection of candidate items. Again, the uniform case is much simpler. An array of size <span class="math inline">\(n\)</span>, initialized with the natural sequence, can be used for storing the candidate items. The selection of the item corresponds to choosing an index at random in this array. Removal of an item with known index can be done in <span class="math inline">\(O(1)\)</span> time by simply replacing it with the last item in the array and truncating the array by one.</p>
<p>For the non-uniform case, lines  and  in  can be implemented with a data structure that maintains a subdivision of an interval into <span class="math inline">\(n\)</span> subintervals and allows lookups and updates. Walker’s alias method seems to be ill-suited for this purpose, as each item potentially spreads over several “boxes”, and an efficient update algorithm seems elusive. <span class="citation">@Wong__1980</span> propose a data structure similar to a heap that can be initialized in <span class="math inline">\(O(n)\)</span> time and supports simultaneous lookup and update in <span class="math inline">\(O(\log n)\)</span> time, the reader is referred to the original paper for details.</p>
</div>
<div id="sampling-according-to-selection-probabilities" class="section level2">
<h2 class="hasAnchor">
<a href="#sampling-according-to-selection-probabilities" class="anchor"></a>Sampling according to selection probabilities</h2>
<p><span class="citation">@Tille_Sampl.Algorithms_2006b</span> defines a more rigorous framework for sampling algorithms from the perspective of the likelihood that a sample is selected based on a given sampling design. In the context of that framework,  belongs to the class of “draw by draw” algorithms. For the application of sampling theory, the order of the selected elements is not important and usually ignored; in contrast,  returns an ordered sequence of sampled elements.</p>
</div>
</div>
<div id="implementation" class="section level1">
<h1 class="hasAnchor">
<a href="#implementation" class="anchor"></a>Implementation</h1>
<p> offers reasonably efficient implementations for all cases except non-uniform sampling without replacement. The stock implementation for weighted random sampling without replacement requires <span class="math inline">\(O(n \cdot s)\)</span> run time, which is equivalent to <span class="math inline">\(O(n^2)\)</span> if <span class="math inline">\(s = O(n)\)</span>. This paper explores alternative approaches: rejection sampling, one-pass sampling and reservoir sampling. Only the first can be described formally within the framework of , however an actual implementation would use sampling <em>with</em> replacement as a subroutine. The last two are based on an arithmetic transformation of a weight distribution.</p>
<div id="rejection-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#rejection-sampling" class="anchor"></a>Rejection sampling</h2>
<p>In the framework of , rejection sampling corresponds to flagging sampled items as “invalid” (instead of removing them) in line , and repeating the sampling in line  until hitting a valid item. Note that the distribution of the result is not modified if invalid items are purged occasionally. This corresponds to the class of “rejective algorithms” in the framework of <span class="citation">@Tille_Sampl.Algorithms_2006b</span>.</p>
<p>Therefore, sampling without replacement can be emulated by repeated sampling with replacement, as shown in . The general idea is to sample slightly more items than necessary (with replacement), and then to throw away the duplicate items. If the resulting sequence of items is shorter than requested, the result for a much smaller problem is appended. In , duplicate items in the result of a sampling with replacement (line ) correspond to invalid items in the rejection sampling, and the recursive call in line  corresponds to purging the invalid items.</p>
\begin{algorithm}
  \caption{$\text{sample.rej}(n, s, p_i)$}
  \label{alg:sample-rej}
  \begin{algorithmic}[1]
    \REQUIRE $n$: Size of the population
    \REQUIRE $s$: Number of items to sample
    \REQUIRE $p_i$: Weight of each item for $i \in \{1,\ldots,n\}$
    \ENSURE Returns a vector $k_j \in \{1,\ldots,n\}$ for
      $j \in \{1,\ldots,s\}$ that contains the indexes of the items sampled
    \STATE
      $k_i \leftarrow \text{unique}(\text{sample}(n, \text{expected.items}(n, s), \TRUE, p_i))$ \hfill \pairadice{}
      \label{alg:sample-rej:sample}
    \STATE $l \leftarrow \text{length}(k_i)$
    \IF{$l \geq s$}
      \RETURN the first $s$ items of $k_i$
    \ENDIF
    \STATE remove items $k_i$ from $p_i$\label{alg:sample-rej:remove}
    \RETURN $k_i \oplus \text{sample.rej}(n - l, s - l, p_i)$\label{alg:sample-rej:rec}
  \end{algorithmic}
\end{algorithm}
<p>Here, <span class="math inline">\(\text{expected.items}(n, s)\)</span> is an estimate for the number of items that need to be drawn with replacement, so that the result can be expected to contain at least <span class="math inline">\(s\)</span> unique items. (An incorrect estimate only affects the run time, not the correctness of the algorithm.) Note that, with <span class="math inline">\(\text{expected.items}(n, s) = 1\)</span> everywhere,  are in fact identical. For a uniform distribution, it can be shown that the result has approximately <span class="math inline">\(s\)</span> unique items in expectation with <span class="math inline">\(\text{expected.items}(n, s) = n (H_n - H_{n-s}) = n \sum_{i=n-s+1}^n \frac{1}{i}\)</span>. This is an underestimate for non-uniform distributions. Nevertheless, the implementation in this package uses this estimate, capped at <span class="math inline">\(2n\)</span>. As shown in , this algorithm performs worse than the alternatives shown in the following section in the majority of cases, but still better than the stock implementation for large values of <span class="math inline">\(n\)</span> and <span class="math inline">\(s\)</span>. Therefore, no tuning of the estimation of the number of expected items has been carried out.</p>
</div>
<div id="one-pass-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#one-pass-sampling" class="anchor"></a>One-pass sampling</h2>
<p>A particularly interesting algorithm has been devised only recently by <span class="citation">@efraimidis_weighted_2006</span>. In the simplest version (here referred to as <em>one-pass sampling</em>), it is sufficient to draw <span class="math inline">\(n\)</span> random numbers, combine them arithmetically with the weight distribution <span class="math inline">\(p_i\)</span>, and perform a partial sort to find the indexes of the <span class="math inline">\(s\)</span> smallest items.  is a modified version of Algorithm A in the original paper that operates on the logarithmic scale for increased numerical stability.</p>
\begin{algorithm}
  \caption{$\text{sample.rank}(n, s, p_i)$}
  \label{alg:sample-rank}
  \begin{algorithmic}[1]
    \REQUIRE $n$: Size of the population
    \REQUIRE $s$: Number of items to sample
    \REQUIRE $p_i$: Weight of each item for $i \in \{1,\ldots,n\}$
    \ENSURE Returns a vector $k_j \in \{1,\ldots,n\}$ for
      $j \in \{1,\ldots,s\}$ that contains the indexes of the items sampled
    \STATE 
      $r_i \leftarrow \text{Exp}(1) / p_i$ for all $i \in \{1,\ldots,n\}$ \hfill \pairadice{}
      \label{alg:sample-rank:sample}
    \RETURN the positions of the $s$ smallest elements in $r_i$\label{alg:sample-rank:rec}
  \end{algorithmic}
\end{algorithm}
<p>The arithmetic transformation of the weight distribution is carried out in line . A sequence of i.i.d. samples from the exponential distribution with rate 1 is divided by the weights, the order of the results defines the sampling order. Intuitively, an item with a large weight has a larger probability of appearing earlier in this sorting order. <span class="citation">@efraimidis_weighted_2006</span> prove that  are equivalent.</p>
<p>The algorithm amazes with its elegance and simplicity. This also allows for almost trivial parallelization, provided that independent random number generators are available to each thread. Computational complexity is dominated by the partial sort (which can be implemented in <span class="math inline">\(O(n + s \log n)\)</span>, or even in <span class="math inline">\(O(n)\)</span> for floating-point numbers <span class="citation">[@terdiman_radix_2000]</span>. However, the cost of generating <span class="math inline">\(n\)</span> random variates may outweigh the cost for sorting even for moderately large values of <span class="math inline">\(s\)</span>. The next subsection describes an extension to overcome this issue.</p>
</div>
<div id="reservoir-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#reservoir-sampling" class="anchor"></a>Reservoir sampling</h2>
<p><em>Reservoir sampling with exponential jumps</em> is a modified version of one-pass sampling. A reservoir of “active” items is maintained. Each generated random number decides how many input items are skipped until the current “least likely” item is removed from the reservoir.  shows a verbal description, further details and formal proofs of correctness are beyond the scope of this paper and can be found in <span class="citation">[@efraimidis_weighted_2006]</span>. Only <span class="math inline">\(O(s \log \frac{n}{s})\)</span> random numbers (in expectation) are needed with this extension, whereas the simple version always requires <span class="math inline">\(n\)</span> random numbers. The exponential jumps method requires fewer updates of the reservoir (and therefore fewer random numbers and less run time) if the weights are arranged in descending order. In addition to drawing random numbers, the extraction of the smallest item from a priority queue (line ) is the most expensive operation.</p>
\begin{algorithm}[t]
  \caption{$\text{sample.expj}(n, s, p_i)$}
  \label{alg:sample-expj}
  \begin{algorithmic}[1]
    \REQUIRE $n$: Size of the population
    \REQUIRE $s$: Number of items to sample
    \REQUIRE $p_i$: Weight of each item for $i \in \{1,\ldots,n\}$
    \ENSURE Returns a vector $k_j \in \{1,\ldots,n\}$ for
      $j \in \{1,\ldots,s\}$ that contains the indexes of the items sampled
    \STATE Initialize reservoir with the first $s$ elements
    \STATE
      Set keys for these elements based on their weight and one random number per item \hfill \pairadice{}
    \WHILE{not all items processed}
      \STATE Choose item with lowest key in the reservoir
        \label{alg:sample-expj:pq}
      \STATE
        Determine number of items to skip, based on this key and a random number \hfill \hfill \pairadice{}
      \STATE Find and remove item with the lowest key in the reservoir
      \STATE Add current item to the reservoir
      \STATE
        Set the key of the new item based on its weight and a random number \\ \hfill \pairadice{}
    \ENDWHILE
    \RETURN Items in reservoir sorted by their key
  \end{algorithmic}
\end{algorithm}
</div>
</div>
<div id="implementation-1" class="section level1">
<h1 class="hasAnchor">
<a href="#implementation-1" class="anchor"></a>Implementation</h1>
<p>The  package <span class="citation">[@Muller_2018]</span> contains implementations for the algorithms presented in the previous section: One  implementation of rejection sampling (, denoted by <em>rej</em>), two implementations ( and ) of one-pass sampling (, <em>rank</em> and <em>crank</em>), and one  implementation of reservoir sampling with exponential jumps (<em>expj</em>, ). The  package <span class="citation">[@Eddelbuettel_2011; @Eddelbuettel_2013; @Eddelbuettel_2017]</span> is used to generate the glue between  and .</p>
<p>In the package, the functions are prefixed with <code>sample_int_</code>. All functions share the same interface, the function arguments correspond to those of : <code>size</code> is the <span class="math inline">\(s\)</span> argument, and <code>prob</code> is the <span class="math inline">\(p_i\)</span> argument. For testing the new routines against the  implementation, a wrapper function <code><a href="../../reference/sample_int.html">sample_int_R()</a></code> is provided, which calls the base  function <code>sample.int()</code> with <code>replace = FALSE</code>.</p>
<p>The  implementations are very similar to the pseudocode: As an example, the <em>rank</em> implementation is shown below.</p>
<pre><code>function (n, size, prob) 
{
    .check_args(n, size, prob)
    head(order(rexp(n)/prob), size)
}
&lt;environment: namespace:wrswoR&gt;</code></pre>
<p>The <em>crank</em> implementation has been somewhat optimized for cache efficiency. Due to its relative complexity, the <em>expj</em> implementation is kept very close to the pseudocode in the original paper, still this function also operates on the logarithmic scale for numerical stability. The transformation works in a fashion very similar to that of .</p>
<p>The remainder of this paper presents performance characteristics and a validation of the new implementations.</p>
</div>
<div id="performance" class="section level1">
<h1 class="hasAnchor">
<a href="#performance" class="anchor"></a>Performance</h1>
<p></p>
<p>This section presents run time tests for various combinations of input parameters, attempts to provide guidance when to choose which implementation, and discusses the correctness of the implementation. All test results shown in this section are based on data available in the  package <span class="citation">[@Muller_2017]</span>.</p>
<div id="input-parameters" class="section level2">
<h2 class="hasAnchor">
<a href="#input-parameters" class="anchor"></a>Input parameters</h2>
<p>The run time tests used different values for the function arguments <span class="math inline">\(n\)</span>, <span class="math inline">\(s\)</span> and <span class="math inline">\(prob\)</span>. Instead of directly specifying <span class="math inline">\(s\)</span>, it is given as a proportion of <span class="math inline">\(n\)</span>, denoted by <span class="math inline">\(r = \frac{s}{n}\)</span>. The following weight distributions (used for <span class="math inline">\(p_i\)</span>) were tested:</p>
\begin{description}
  \item[uniform] $p_i = 1$ everywhere
  \item[linear] Sequence from $1$ to $n$ ($\{p_i\} = \{1,\ldots n\}$),
  \emph{ascending} ($\nearrow$), \emph{descending} ($\searrow$) and
  \emph{shuffled} ($\leadsto$)
  \item[geometric] Starting at $1$, the weight is multiplied with a constant $\alpha$ for each step
  ($p_{i+1} = \alpha p_i$, \emph{ascending}, \emph{descending},
  and \emph{shuffled});
  the constant is chosen so that both minimal and maximal weights
  and the sum of weights is still representable as a floating-point number.
\end{description}
<p>The geometric case is very extreme and unlikely to occur in practice, it is included here to test potential limitations of the implementations.</p>
<pre><code>## `kimisc::ofactor()` is deprecated, use `forcats::fct_inorder()` instead.</code></pre>
</div>
<div id="run-time" class="section level2">
<h2 class="hasAnchor">
<a href="#run-time" class="anchor"></a>Run time</h2>
<p>The run time was measured using the  package <span class="citation">[@Mersmann_2018]</span> in block order with a warmup of 10 iterations using the default 100 iterations. The tests ran on a single core of an Intel Xeon CPU X5680 clocked at 3.33 GHz with 12 MB cache, running Red Hat Enterprise Linux Server release 7.2,  version 3.2.3, and version 0.4 of the  package.</p>
<p> presents an overview of the median run time for different input sizes, output size ratios, weight distributions and implementations. The  implementation is outperformed by all other implementations for <span class="math inline">\(n \approx 10000\)</span>, in many cases even for much smaller inputs. In the log-log scale used here, the slope of the curves translates to computational complexity; the steeper slope for the  implementation corresponds to its quadratic complexity compared to the only slightly superlinear complexity of the other algorithms. No data were obtained for the  and <em>rej</em> implementations if the computation would have taken too long, this is reflected by a premature ending of the corresponding curves in .</p>
<div class="figure">
<img src="wrswoR_files/figure-html/run-time-log-1.png" alt="Median run times" width="672"><p class="caption">
Median run times
</p>
</div>
<p>As expected, the <em>expj</em> implementation is among the fastest, especially for <span class="math inline">\(r \ll 1\)</span>. In the case <span class="math inline">\(r = 0.01\)</span> for the <em>geometric ascending</em> distribution, the new implementations win only by a margin; in particular, the run time of <em>expj</em> depends on the ordering of the weights which is unfavorable here.</p>
<p>The <em>rej</em> and <em>rank</em> implementations exhibit initial costs on the sub-millisecond scale even for small input sizes, probably due to the fact that both are implemented purely in . In addition, the <em>rej</em> code is by far the slowest (but still faster than the stock implementation) for <em>geometric</em> distributions, because in each step only a tiny fraction of items have a non-negligible weight, and hence most sampled items are rejected as duplicates (line  of ).</p>
<p> compares run times for <em>crank</em> and <em>expj</em> for the different weight distributions, values above 1 mean that <em>expj</em> is faster. The <em>expj</em> implementation seems to perform better than <em>crank</em> if <span class="math inline">\(r\)</span> is small or <span class="math inline">\(n\)</span> is large. For the pathological <em>geometric</em> cases, the run time differences between <em>ascending</em> and <em>descending</em> weights are substantial for small <span class="math inline">\(r\)</span>. The advantage of the <em>expj</em> code for <span class="math inline">\(r = 1\)</span> and large <span class="math inline">\(n\)</span> is surprising and can only be explained with differences in run time between partial sort (which is used for <em>crank</em>) and priority queue (for <em>expj</em>).</p>
<div class="figure">
<img src="wrswoR_files/figure-html/run-time-crank-expj-1.png" alt="Comparison of \emph{crank} and \emph{expj} run times" width="672"><p class="caption">
Comparison of  and  run times
</p>
</div>
<p>For the break-even analysis, <em>expj</em> is compared to the stock implementation in  for linear ascending weights. The <em>expj</em> implementation can be up to about 2 times slower than the stock implementation, for absolute run times of around 10 microseconds for <span class="math inline">\(n = 100\)</span>. It is remarkable that the relative performance of <em>expj</em> is worst with <span class="math inline">\(r = 0.1\)</span> in this case. The relative slowness of the stock implementation for the case <span class="math inline">\(r = 0.01\)</span> is due to a mandatory pre-sorting of weights using heap sort even for <span class="math inline">\(s = 1\)</span>, which is not required for <em>expj</em>.</p>
<div class="figure">
<img src="wrswoR_files/figure-html/run-time-break-even-1.png" alt="Comparison of \proglang{R} and \emph{expj} run times for linear ascending weights" width="672"><p class="caption">
Comparison of  and  run times for linear ascending weights
</p>
</div>
<p> shows a more detailed break-even point analysis for a larger choice for <span class="math inline">\(r\)</span> and for all weight distributions tested. Compared to <em>expj</em>, the stock implementation performs best with a uniform weight distribution, offsetting the break-even point to just below 500 for the best choice of <span class="math inline">\(r \approx 0.1\)</span>. In other words, for <span class="math inline">\(n &lt; 500\)</span> and <span class="math inline">\(s = \lceil 0.1n \rceil\)</span>, the stock implementation is still the best choice in the case of a uniform or near-uniform distribution, with a speedup of at most 2.12.</p>
<div class="figure">
<img src="wrswoR_files/figure-html/point-break-even-1.png" alt="Break-even point of \proglang{R} and \emph{expj} run times" width="672"><p class="caption">
Break-even point of  and  run times
</p>
</div>
<p>Because the order of the weights has an effect on the run time, it is worthwhile to evaluate if a prior sorting step may lead to better performance. The run time required for sorting has been measured on the same computing environment for the different weights distributions and problem sizes tested. For large samples, radix sort <span class="citation">[@terdiman_radix_2000]</span> is almost always the fastest alternative. The median of the overheads of sampling from a shuffled distribution of weights (w.r.t. the same distribution sorted in decreasing order) is compared with the corresponding cost of sorting in . It seems that prior sorting cannot reduce the overall run time.</p>
<div class="figure">
<img src="wrswoR_files/figure-html/overhead-sorting-1.png" alt="Overhead of unsorted data vs.\ sorting costs" width="672"><p class="caption">
Overhead of unsorted data vs. sorting costs
</p>
</div>
</div>
</div>
<div id="correctness" class="section level1">
<h1 class="hasAnchor">
<a href="#correctness" class="anchor"></a>Correctness</h1>
<p>This section aims at validating the new implementations. A correct implementation should satisfy the following criteria:</p>
<ol style="list-style-type: decimal">
<li>All output items are between <span class="math inline">\(1\)</span> and <span class="math inline">\(n\)</span>.</li>
<li>Each item occurs at most once in the output.</li>
<li>For given parameters <span class="math inline">\(n\)</span>, <span class="math inline">\(s\)</span> and <span class="math inline">\(p_i\)</span>, the probability that item <span class="math inline">\(i\)</span> is at position <span class="math inline">\(j\)</span> in the output (with <span class="math inline">\(1 \leq i \leq n\)</span> and <span class="math inline">\(1 \leq j \leq s\)</span>) is identical for the implementation under test and the stock implementation.</li>
</ol>
<p>Verifying these criteria seems to be challenging due to the stochasticity of the algorithms. The first two can be simply checked by observing the output. The following subsection describes a procedure for checking the third criterion.</p>
<div id="methodology" class="section level2">
<h2 class="hasAnchor">
<a href="#methodology" class="anchor"></a>Methodology</h2>
<p>For fixed <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> and for fixed parameters <span class="math inline">\(n\)</span>, <span class="math inline">\(s\)</span>, and <span class="math inline">\(p_i\)</span>, each call to the sampling routine is a Bernoulli trial with fixed success probability <span class="math inline">\(\pi_{i,j}\)</span>. Repeated sampling leads to an i.i.d. sequence of Bernoulli trials. In general, computing the exact value of <span class="math inline">\(\pi_{i,j}\)</span> for large <span class="math inline">\(j\)</span> seems to require considerable computational resources. Therefore, the value of <span class="math inline">\(\pi_{i,j}\)</span> is assumed unknown, and only the equality of the proportions is tested for the different implementations using a two-sided test for equal proportions (essentially a <span class="math inline">\(\chi^2\)</span> test, implemented by the <code>prop.test()</code> function). The correctness check is performed as follows:</p>
<ul>
<li>The parameters <span class="math inline">\(n\)</span>, <span class="math inline">\(s\)</span>, and <span class="math inline">\(p_i\)</span>, and the implementation under test, are fixed.</li>
<li>For both the tested and the stock implementation, <span class="math inline">\(N\)</span> random samples without replacement are drawn and recorded.</li>
<li>For all <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, the number of samples where item <span class="math inline">\(i\)</span> is in position <span class="math inline">\(j\)</span> (denoted by <span class="math inline">\(f_{i,j}\)</span>) is computed.</li>
<li>The counts are tested for equality of proportions, yielding a p-value for each tuple <span class="math inline">\((i, j)\)</span>.</li>
</ul>
<p>In this setting, for fixed <span class="math inline">\((i, j)\)</span>, the p-value is itself a random variable that is distributed uniformly over <span class="math inline">\((0, 1]\)</span> under the null hypothesis of equal proportions (i.e., if the tested implementation is correct). On the other hand, if the implementation is faulty, the rejection rate for the null hypothesis will be large, and a substantial share of the p-values will be very close to 0. While this procedure does not constitute a proof of correctness, it offers a means to automatically test the implementations for nontrivial errors. A similar procedure (using a visual representation with violin plots) caught an implementation error in the <em>expj</em> code that occurred only in the case <span class="math inline">\(1 &lt; s &lt; n\)</span>.</p>
<p>To assert the sensitivity of the testing procedure, a faulty implementation was simulated by passing altered weights to R’s implementation. The modification consists of updating <span class="math display">\[p_i^\prime \coloneqq p_i \cdot \left(1 + \text{skew} \cdot \frac{i - 1}{n - 1}\right),\]</span> where a skew of zero means no change, and a skew of 1% corresponds to relative differences increasing between  and .</p>
<p>The test for equal proportions can be substituted by Fisher’s exact test, which tends to produce lower p-values and therefore is usually more powerful than the test for equal proportions. However, Fisher’s exact test has <span class="math inline">\(O(N)\)</span> complexity, because it evaluates the density of the hypergeometric distribution on a support of the order of <span class="math inline">\(N\)</span>. Using this test would have been prohibitive in the setting described here.</p>
</div>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p> shows a Schweder plot <span class="citation">[@Schweder_Biometrika_1982]</span> of the p-values resulting from an experiment that draws <span class="math inline">\(N = 2^{22}\)</span> samples for <span class="math inline">\(n = 7\)</span>, <span class="math inline">\(s = 4\)</span>, and a geometric weight distribution with <span class="math inline">\(\alpha = 1.08\)</span>, using all five implementations. Different values of <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are denoted with different colors and shapes. The theoretical distribution is shown as a dotted line, and aligns very well with the observed p-values. Fisher’s combined probability test is a meta-analysis method that combines multiple p-values (from different but related studies) into one; it is implemented in the  package <span class="citation">[@Dewey_2017]</span>. For this particular run of the experiment, Fisher’s method cannot reject the null hypothesis of uniformity (<span class="math inline">\(p = 0.896\)</span>).</p>
<p>As an example for a positive test,  shows results for the same experiment, now substituting the stock implementation with a faulty one with <span class="math inline">\(\text{skew} = \ensuremath{0.25\,\%}\)</span>. Despite the relative similarity of the weight distributions, the distribution of the p-values deviates substantially from the uniform distribution, with more p-values close to zero than expected. Here, Fisher’s method detects significant, although not overwhelming, evidence against the null hypothesis (<span class="math inline">\(p = 0.0183\)</span>).</p>
<div class="figure">
<img src="wrswoR_files/figure-html/correctness-true-1.png" alt="Schweder plot for p-values resulting from comparing the \emph{crank} and \proglang{R} implementations" width="672"><p class="caption">
Schweder plot for p-values resulting from comparing the  and  implementations
</p>
</div>
<div class="figure">
<img src="wrswoR_files/figure-html/correctness-false-1.png" alt="Schweder plot for p-values resulting from comparing the \proglang{R} implementation with a skewed version of itself" width="672"><p class="caption">
Schweder plot for p-values resulting from comparing the  implementation with a skewed version of itself
</p>
</div>
</div>
<div id="results" class="section level2">
<h2 class="hasAnchor">
<a href="#results" class="anchor"></a>Results</h2>
<p>A fairly comprehensive test also has been carried out, covering all <span class="math inline">\(n \in \{ 2, \dots80 \}\)</span>, a subset of <span class="math inline">\(s \in \{1, \ldots, n\}\)</span>, and all <span class="math inline">\((i, j)\)</span>. For each combination, the cell frequencies <span class="math inline">\(f_{i,j}\)</span> were collected for all new implementations, and for the stock implementation with and without altered weights (using <span class="math inline">\(\text{skew}\)</span> values between  and ), for <span class="math inline">\(N\)</span> ranging from <span class="math inline">\(2^{10}\)</span> to <span class="math inline">\(2^{24}\)</span> (only powers of <span class="math inline">\(2\)</span>). Each cell frequency was compared to that of the stock implementation. This resulted in around 500 million p-values, which were again combined using Fisher’s method.</p>
<p> shows the results of the meta-analysis separately for each <span class="math inline">\(N\)</span> and for each (supposedly correct or faulty) implementation. Comparing the stock implementation to itself (using different random seeds) resulted in a p-value of almost 1 for all <span class="math inline">\(N\)</span>, the same holds for all new codes. On the other hand, all skews tested led to strong rejection of the correctness hypothesis (p-value effectively 0) sooner or later; as expected, the smaller the skew, the larger the <span class="math inline">\(N\)</span> that is required for rejection.</p>
<div class="figure">
<img src="wrswoR_files/figure-html/comprehensive-1.png" alt="Combining p-values for a comprehensive test" width="672"><p class="caption">
Combining p-values for a comprehensive test
</p>
</div>
<p>This comparison is less sensitive to implementation errors that occur only for specific arguments (e.g., if an implementation behaves as expected except if <span class="math inline">\(n\)</span> is a power of 2). To catch such deficiencies, it is helpful to analyze finer aggregates of the p-values.  shows combined p-values separately for all pairs of <span class="math inline">\(n\)</span> and <span class="math inline">\(N\)</span> when comparing each new code to the stock implementation. Some p-values are in the range of <span class="math inline">\((0.01, 0.1]\)</span> or even <span class="math inline">\(\left(10^{-4}, 0.01\right]\)</span>, but this can be expected due to the uniform distribution of the p-values under the null hypothesis. The plot in  is similar, but shows the p-values that result from comparing the stock implementation with a skewed version of itself, for different skews. Here, for all skews except 0, the combined p-value approaches zero sooner or later as <span class="math inline">\(N\)</span> increases.</p>
<div class="figure">
<img src="wrswoR_files/figure-html/comprehensive-true-1.png" alt="Combined p-values for different values of $n$ and $N$, resulting from comparing each new code to the stock implementation" width="672"><p class="caption">
Combined p-values for different values of <span class="math inline">\(n\)</span> and <span class="math inline">\(N\)</span>, resulting from comparing each new code to the stock implementation
</p>
</div>
<div class="figure">
<img src="wrswoR_files/figure-html/comprehensive-false-1.png" alt="Combined p-values for different values of $n$ and $N$, resulting from comparing the stock implementation to a skewed version of itself" width="672"><p class="caption">
Combined p-values for different values of <span class="math inline">\(n\)</span> and <span class="math inline">\(N\)</span>, resulting from comparing the stock implementation to a skewed version of itself
</p>
</div>
</div>
</div>
<div id="conclusion" class="section level1">
<h1 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h1>
<p>This paper describes four new implementations for weighted random sampling without replacement in : Rejection sampling, two implementations of one-pass sampling, and reservoir sampling with exponential jumps. The new implementations, even those written in pure , clearly outperform the one provided by the  package if the number of items to choose from is just above 10000, this threshold is below 500 for reservoir sampling with exponential jumps. Each of the algorithms presented here has its advantages:</p>
<ul>
<li>Rejection sampling is a simple and straightforward method that builds upon weighted sampling with replacement.</li>
<li>One-pass sampling can be parallelized easily.</li>
<li>Reservoir sampling with exponential jumps is fast even for degenerate weight distributions, and economical in its use of random numbers.</li>
</ul>
<p>In particular, reservoir sampling with exponential jumps <span class="citation">[@efraimidis_weighted_2006]</span> requires just about double the time of the stock implementation in the worst case, code optimization (such as using a cache-efficient heap structure for the priority queue) might help further reduce this threshold or even remove it entirely. Reservoir sampling performs best if large weights tend to occur before small weights, but a prior sorting step does not seem to improve run time.</p>
<p>For validation, the new implementations have been compared with the stock implementation by counting the number of occurrences for each item and each possible position in a large number of runs, and testing the null hypothesis of equal proportions. This yields a massive number of p-values, which can be combined using Fisher’s method, a meta-analysis technique. The validation methodology is able to clearly detect an emulated implementation error, which consisted of skewing the input frequency distribution in a predefined fashion, whereas no difference between the new and the stock implementations could be measured. So far, the detection of non-systematic errors or other failure modes have not been tested.</p>
<p>In order to include a faster sampling algorithm into base , an implementation in  seems necessary. Other platforms for scientific computing, such as  or , would also benefit if this implementation was provided in an open-source library with a documented interface.</p>
<p>For the current implementation in , a user might not expect a natural operation such as random sampling to take excessive time, without the ability to interrupt it. Allowing to interrupt execution in the current implementation (via <code>R_CheckUserInterrupt()</code>) would at least save the unaware user the frustration of a lost workspace.</p>
<p>The algorithms presented here generate an ordered sample of items based on relative weights. If the relative importance is instead given as inclusion probabilities, and the order of the items is irrelevant, e.g., as in the application of survey sampling, the <code>UPxxx()</code> functions in the  package <span class="citation">[@Tille_2016]</span> offer a viable alternative.</p>
</div>
<div id="acknowledgments" class="section level1">
<h1 class="hasAnchor">
<a href="#acknowledgments" class="anchor"></a>Acknowledgments</h1>
<p>The author would like to thank the Swiss National Science Foundation for financial support (grant 138270). This work would have been much more difficult without the  and  packages <span class="citation">[@Bischl_2015]</span>. The  <span class="citation">[@Wickham_2017]</span> and  packages <span class="citation">[@Wickham_2018]</span> helped processing the data; the plots were created with  <span class="citation">[@Wickham_2009]</span> and rendered with  <span class="citation">[@Sharpsteen_2016]</span>. This paper was created using  <span class="citation">[@Xie_2018; @Xie_2015; @Xie_2014]</span> and  <span class="citation">[@Allaire_2017]</span>, based on a template provided by  <span class="citation">[@Allaire_2017a]</span>.</p>
\bibliography{wrswoR}
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li>
<a href="#sampling-from-discrete-populations">Sampling from discrete populations</a><ul class="nav nav-pills nav-stacked">
<li><a href="#sampling-with-replacement">Sampling with replacement</a></li>
      <li><a href="#sampling-without-replacement">Sampling without replacement</a></li>
      <li><a href="#sampling-according-to-selection-probabilities">Sampling according to selection probabilities</a></li>
      </ul>
</li>
      <li>
<a href="#implementation">Implementation</a><ul class="nav nav-pills nav-stacked">
<li><a href="#rejection-sampling">Rejection sampling</a></li>
      <li><a href="#one-pass-sampling">One-pass sampling</a></li>
      <li><a href="#reservoir-sampling">Reservoir sampling</a></li>
      </ul>
</li>
      <li><a href="#implementation-1">Implementation</a></li>
      <li>
<a href="#performance">Performance</a><ul class="nav nav-pills nav-stacked">
<li><a href="#input-parameters">Input parameters</a></li>
      <li><a href="#run-time">Run time</a></li>
      </ul>
</li>
      <li>
<a href="#correctness">Correctness</a><ul class="nav nav-pills nav-stacked">
<li><a href="#methodology">Methodology</a></li>
      <li><a href="#example">Example</a></li>
      <li><a href="#results">Results</a></li>
      </ul>
</li>
      <li><a href="#conclusion">Conclusion</a></li>
      <li><a href="#acknowledgments">Acknowledgments</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Kirill Müller.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
