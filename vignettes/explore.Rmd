---
title: "Exploring timing data"
author: "Kirill MÃ¼ller"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Exploring timing data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r}
library(wrswoR)
library(ggplot2)
library(dplyr)
library(tidyr)
```

# Run time tests

- Input sizes: `r unique(timings$n)`
- Probability distributions: `r unique(timings$prob)`
- Algorithms: `r unique(timings$expr)`
- Total measurements: `r nrow(timings)`

Clearly worse performance of R implementation for large inputs.

```{r fig.width=7, fig.height=5}
timings %>%
  filter(prob == "uniform") %>%
  ggplot(aes(x=factor(n), y=time * 1e-9, color=expr)) +
  geom_boxplot() +
  scale_y_log10()
```

Compare median and worst performance (for uniform distribution).

```{r fig.width=7, fig.height=5}
timings %>%
  filter(prob == "uniform") %>%
  group_by(n, expr) %>%
  summarize(median = median(time), max = max(time)) %>%
  ungroup %>%
  gather(metric, time, median, max) %>%
  ggplot(aes(x=n, y=time * 1e-9, color=expr)) +
  facet_wrap(~metric, ncol = 1) +
  geom_line() +
  scale_x_log10() +
  scale_y_log10()
```


```{r}
timings %>%
  arrange(prob, n, expr, time) %>%
  group_by(prob, n, expr) %>%
  mutate(id = seq_along(time)) %>%
  ungroup %>%
  spread(prob, time) %>%
  gather_("diff_to", "other_time", unique(timings$prob) %>% setdiff("uniform")) %>%
  mutate(time_diff = (other_time - uniform) / uniform, uniform = NULL, other_time = NULL) %>%
  ggplot(aes(x=factor(n), y=time_diff, color=expr)) +
  facet_wrap(~diff_to) +
  scale_y_continuous(limits = c(-1, 1)) +
  geom_boxplot()
```



# Comparison of results
